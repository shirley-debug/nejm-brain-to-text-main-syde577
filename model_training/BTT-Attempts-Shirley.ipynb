{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Neuroprosthetics-Lab/nejm-brain-to-text.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install redis numpy pandas h5py omegaconf editdistance tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /kaggle/working/nejm-brain-to-text/model_training/evaluate_without_LLM.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import redis\n",
    "from omegaconf import OmegaConf\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import editdistance\n",
    "import argparse\n",
    "\n",
    "from rnn_model import GRUDecoder\n",
    "from evaluate_model_helpers import *\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Evaluate a pretrained RNN model on the copy task dataset.')\n",
    "parser.add_argument('--model_path', type=str, default='../data/t15_pretrained_rnn_baseline',\n",
    "                    help='Path to the pretrained model directory (relative to the current working directory).')\n",
    "parser.add_argument('--data_dir', type=str, default='../data/hdf5_data_final',\n",
    "                    help='Path to the dataset directory (relative to the current working directory).')\n",
    "parser.add_argument('--eval_type', type=str, default='test', choices=['val', 'test'],\n",
    "                    help='Evaluation type: \"val\" for validation set, \"test\" for test set. '\n",
    "                         'If \"test\", ground truth is not available.')\n",
    "parser.add_argument('--csv_path', type=str, default='../data/t15_copyTaskData_description.csv',\n",
    "                    help='Path to the CSV file with metadata about the dataset (relative to the current working directory).')\n",
    "parser.add_argument('--gpu_number', type=int, default=1,\n",
    "                    help='GPU number to use for RNN model inference. Set to -1 to use CPU.')\n",
    "args = parser.parse_args()\n",
    "model_path = args.model_path\n",
    "data_dir = args.data_dir\n",
    "eval_type = args.eval_type  \n",
    "b2txt_csv_df = pd.read_csv(args.csv_path)\n",
    "model_args_path = os.path.join(model_path, 'args.yaml')\n",
    "if not os.path.exists(model_args_path):\n",
    "    model_args_path = os.path.join(model_path, 'checkpoint/args.yaml')\n",
    "print(f\"Loading model args from: {model_args_path}\")\n",
    "model_args = OmegaConf.load(model_args_path)\n",
    "gpu_number = args.gpu_number\n",
    "if torch.cuda.is_available() and gpu_number >= 0:\n",
    "    if gpu_number >= torch.cuda.device_count():\n",
    "        raise ValueError(f'GPU number {gpu_number} is out of range. Available GPUs: {torch.cuda.device_count()}')\n",
    "    device = f'cuda:{gpu_number}'\n",
    "    device = torch.device(device)\n",
    "    print(f'Using {device} for model inference.')\n",
    "else:\n",
    "    if gpu_number >= 0:\n",
    "        print(f'GPU number {gpu_number} requested but not available.')\n",
    "    print('Using CPU for model inference.')\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Model definition\n",
    "model = GRUDecoder(\n",
    "    neural_dim = model_args['model']['n_input_features'],\n",
    "    n_units = model_args['model']['n_units'], \n",
    "    n_days = len(model_args['dataset']['sessions']),\n",
    "    n_classes = model_args['dataset']['n_classes'],\n",
    "    rnn_dropout = model_args['model']['rnn_dropout'],\n",
    "    input_dropout = model_args['model']['input_network']['input_layer_dropout'],\n",
    "    n_layers = model_args['model']['n_layers'],\n",
    "    patch_size = model_args['model']['patch_size'],\n",
    "    patch_stride = model_args['model']['patch_stride'],\n",
    ")\n",
    "\n",
    "# Checkpoint\n",
    "checkpoint_path = os.path.join(model_path, 'best_checkpoint')\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    checkpoint_path = os.path.join(model_path, 'checkpoint/best_checkpoint')\n",
    "print(f\"Loading model checkpoint from: {checkpoint_path}\")\n",
    "checkpoint = torch.load(checkpoint_path, weights_only=False, map_location=device)\n",
    "for key in list(checkpoint['model_state_dict'].keys()):\n",
    "    checkpoint['model_state_dict'][key.replace(\"module.\", \"\")] = checkpoint['model_state_dict'].pop(key)\n",
    "    checkpoint['model_state_dict'][key.replace(\"_orig_mod.\", \"\")] = checkpoint['model_state_dict'].pop(key)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])  \n",
    "model.to(device) \n",
    "model.eval()\n",
    "\n",
    "# Loss function\n",
    "ctc_loss = torch.nn.CTCLoss(blank=0, reduction='mean', zero_infinity=False)\n",
    "\n",
    "# Data loading loop\n",
    "test_data = {}\n",
    "total_test_trials = 0\n",
    "for session in model_args['dataset']['sessions']:\n",
    "    if not os.path.exists(os.path.join(data_dir, session)):\n",
    "        print(f\"Session folder not found: {os.path.join(data_dir, session)}, skipping.\")\n",
    "        continue\n",
    "    files = [f for f in os.listdir(os.path.join(data_dir, session)) if f.endswith('.hdf5')]\n",
    "    if f'data_{eval_type}.hdf5' in files:\n",
    "        eval_file = os.path.join(data_dir, session, f'data_{eval_type}.hdf5')\n",
    "        data = load_h5py_file(eval_file, b2txt_csv_df)\n",
    "        test_data[session] = data\n",
    "        total_test_trials += len(test_data[session][\"neural_features\"])\n",
    "        print(f'Loaded {len(test_data[session][\"neural_features\"])} {eval_type} trials for session {session}.')\n",
    "print(f'Total number of {eval_type} trials: {total_test_trials}')\n",
    "print()\n",
    "\n",
    "with tqdm(total=total_test_trials, desc='Predicting phoneme sequences', unit='trial') as pbar:\n",
    "    for session, data in test_data.items():\n",
    "\n",
    "        data['logits'] = []\n",
    "        data['pred_seq'] = []\n",
    "        data['losses'] = [] \n",
    "        input_layer = model_args['dataset']['sessions'].index(session)\n",
    "        \n",
    "        for trial in range(len(data['neural_features'])):\n",
    "            neural_input = data['neural_features'][trial]\n",
    "            neural_input = np.expand_dims(neural_input, axis=0)\n",
    "            dtype = torch.bfloat16 if device.type != 'cpu' else torch.float32\n",
    "            neural_input_tensor = torch.tensor(neural_input, device=device, dtype=dtype)\n",
    "            \n",
    "            with torch.no_grad(): \n",
    "                # runSingleDecodingStep returns a numpy array\n",
    "                logits_numpy = runSingleDecodingStep(neural_input_tensor, input_layer, model, model_args, device)\n",
    "            \n",
    "            # Store the numpy array for phoneme extraction later\n",
    "            data['logits'].append(logits_numpy)\n",
    "            \n",
    "            if eval_type == 'val':\n",
    "                # Convert logits back to a tensor for loss calculation\n",
    "                logits_tensor = torch.tensor(logits_numpy, device=device)\n",
    "            \n",
    "                true_seq = torch.tensor(data['seq_class_ids'][trial][0:data['seq_len'][trial]], device=device, dtype=torch.long)\n",
    "                true_len = torch.tensor([data['seq_len'][trial]], device=device, dtype=torch.long)\n",
    "                # Use the tensor's shape\n",
    "                adjusted_lens = torch.tensor([logits_tensor.shape[1]], device=device, dtype=torch.long)\n",
    "                \n",
    "                # Now perform log_softmax on the tensor\n",
    "                log_probs = torch.permute(logits_tensor.log_softmax(2), [1, 0, 2])\n",
    "                \n",
    "                loss = ctc_loss(log_probs, true_seq, adjusted_lens, true_len)\n",
    "                data['losses'].append(loss.item())\n",
    "\n",
    "            pbar.update(1)\n",
    "pbar.close()\n",
    "\n",
    "for session, data in test_data.items():\n",
    "    data['pred_seq'] = []\n",
    "    for trial in range(len(data['logits'])):\n",
    "        logits = data['logits'][trial][0]\n",
    "        pred_seq = np.argmax(logits, axis=-1)\n",
    "        pred_seq = [int(p) for p in pred_seq if p != 0]\n",
    "        pred_seq = [pred_seq[i] for i in range(len(pred_seq)) if i == 0 or pred_seq[i] != pred_seq[i-1]]\n",
    "        pred_seq = [LOGIT_TO_PHONEME[p] for p in pred_seq]\n",
    "        data['pred_seq'].append(pred_seq)\n",
    "        \n",
    "        if eval_type == 'val':\n",
    "            block_num = data['block_num'][trial]\n",
    "            trial_num = data['trial_num'][trial]\n",
    "            print(f'Session: {session}, Block: {block_num}, Trial: {trial_num}')\n",
    "            sentence_label = data['sentence_label'][trial]\n",
    "            true_seq = data['seq_class_ids'][trial][0:data['seq_len'][trial]]\n",
    "            true_seq = [LOGIT_TO_PHONEME[p] for p in true_seq]\n",
    "            print(f'Sentence label:      {sentence_label}')\n",
    "            print(f'True sequence:       {\" \".join(true_seq)}')\n",
    "            print(f'Predicted Sequence:  {\" \".join(pred_seq)}')\n",
    "            print()\n",
    "\n",
    "output_dir = \"output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, f'phoneme_predictions_{time.strftime(\"%Y%m%d_%H%M%S\")}.csv')\n",
    "\n",
    "ids = []\n",
    "all_pred_phonemes = []\n",
    "all_true_phonemes = []\n",
    "trial_accuracy = []\n",
    "all_losses = [] \n",
    "\n",
    "total_edit_distance = 0\n",
    "total_phoneme_length = 0\n",
    "\n",
    "trial_id = 0\n",
    "for session, data in test_data.items():\n",
    "    if eval_type == 'val':\n",
    "        all_losses.extend(data['losses'])\n",
    "        \n",
    "    for trial_idx, pred_seq in enumerate(data['pred_seq']):\n",
    "        pred_phonemes = ' '.join(pred_seq)\n",
    "        if eval_type == 'val':\n",
    "            true_seq = data['seq_class_ids'][trial_idx][0:data['seq_len'][trial_idx]]\n",
    "            true_phonemes_list = [LOGIT_TO_PHONEME[p] for p in true_seq]\n",
    "            true_phonemes = ' '.join(true_phonemes_list)\n",
    "            \n",
    "            ed = editdistance.eval(pred_seq, true_phonemes_list)\n",
    "            true_len = len(true_phonemes_list)\n",
    "            \n",
    "            total_edit_distance += ed\n",
    "            total_phoneme_length += true_len\n",
    "            \n",
    "            acc = (1 - ed / true_len) if true_len > 0 else 0\n",
    "        else:\n",
    "            true_phonemes = None\n",
    "            acc = None\n",
    "\n",
    "        ids.append(trial_id)\n",
    "        all_pred_phonemes.append(pred_phonemes)\n",
    "        all_true_phonemes.append(true_phonemes)\n",
    "        trial_accuracy.append(acc)\n",
    "        trial_id += 1\n",
    "\n",
    "df_out = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'pred_phonemes': all_pred_phonemes,\n",
    "    'true_phonemes': all_true_phonemes,\n",
    "    'trial_accuracy': trial_accuracy\n",
    "})\n",
    "df_out.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Saved phoneme predictions, true sequences, and trial-level accuracy to {output_file}\")\n",
    "\n",
    "if eval_type == 'val':\n",
    "    if trial_accuracy:\n",
    "        avg_accuracy = sum([a for a in trial_accuracy if a is not None]) / len([a for a in trial_accuracy if a is not None])\n",
    "        print(f\"Average trial-level phoneme accuracy: {avg_accuracy:.4f}\")\n",
    "    else:\n",
    "        print(\"No trials found to calculate accuracy.\")\n",
    "\n",
    "    if total_phoneme_length > 0:\n",
    "        aggregate_per = total_edit_distance / total_phoneme_length\n",
    "        print(f\"Aggregate Phoneme Error Rate (PER): {aggregate_per:.4f}\")\n",
    "    else:\n",
    "        print(\"Could not calculate Aggregate PER: no validation phonemes found.\")\n",
    "        \n",
    "    if all_losses:\n",
    "        avg_loss = sum(all_losses) / len(all_losses)\n",
    "        print(f\"Sum Validation Loss: {sum(all_losses):.4f}\")\n",
    "        print(f\"Average Validation Loss: {avg_loss:.4f}\")\n",
    "    else:\n",
    "        print(\"Could not calculate average validation loss.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /kaggle/working/nejm-brain-to-text/model_training/evaluate_without_LLM.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import redis\n",
    "from omegaconf import OmegaConf\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import editdistance\n",
    "import argparse\n",
    "\n",
    "from rnn_model import GRUDecoder\n",
    "from evaluate_model_helpers import *\n",
    "\n",
    "# (Argument parser, paths, model args, device setup... all unchanged)\n",
    "parser = argparse.ArgumentParser(description='Evaluate a pretrained RNN model on the copy task dataset.')\n",
    "parser.add_argument('--model_path', type=str, default='../data/t15_pretrained_rnn_baseline',\n",
    "                    help='Path to the pretrained model directory (relative to the current working directory).')\n",
    "parser.add_argument('--data_dir', type=str, default='../data/hdf5_data_final',\n",
    "                    help='Path to the dataset directory (relative to the current working directory).')\n",
    "parser.add_argument('--eval_type', type=str, default='test', choices=['val', 'test'],\n",
    "                    help='Evaluation type: \"val\" for validation set, \"test\" for test set. '\n",
    "                         'If \"test\", ground truth is not available.')\n",
    "parser.add_argument('--csv_path', type=str, default='../data/t15_copyTaskData_description.csv',\n",
    "                    help='Path to the CSV file with metadata about the dataset (relative to the current working directory).')\n",
    "parser.add_argument('--gpu_number', type=int, default=1,\n",
    "                    help='GPU number to use for RNN model inference. Set to -1 to use CPU.')\n",
    "args = parser.parse_args()\n",
    "model_path = args.model_path\n",
    "data_dir = args.data_dir\n",
    "eval_type = args.eval_type  \n",
    "b2txt_csv_df = pd.read_csv(args.csv_path)\n",
    "model_args_path = os.path.join(model_path, 'args.yaml')\n",
    "if not os.path.exists(model_args_path):\n",
    "    model_args_path = os.path.join(model_path, 'checkpoint/args.yaml')\n",
    "print(f\"Loading model args from: {model_args_path}\")\n",
    "model_args = OmegaConf.load(model_args_path)\n",
    "gpu_number = args.gpu_number\n",
    "if torch.cuda.is_available() and gpu_number >= 0:\n",
    "    if gpu_number >= torch.cuda.device_count():\n",
    "        raise ValueError(f'GPU number {gpu_number} is out of range. Available GPUs: {torch.cuda.device_count()}')\n",
    "    device = f'cuda:{gpu_number}'\n",
    "    device = torch.device(device)\n",
    "    print(f'Using {device} for model inference.')\n",
    "else:\n",
    "    if gpu_number >= 0:\n",
    "        print(f'GPU number {gpu_number} requested but not available.')\n",
    "    print('Using CPU for model inference.')\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# (Model definition... unchanged)\n",
    "model = GRUDecoder(\n",
    "    neural_dim = model_args['model']['n_input_features'],\n",
    "    n_units = model_args['model']['n_units'], \n",
    "    n_days = len(model_args['dataset']['sessions']),\n",
    "    n_classes = model_args['dataset']['n_classes'],\n",
    "    rnn_dropout = model_args['model']['rnn_dropout'],\n",
    "    input_dropout = model_args['model']['input_network']['input_layer_dropout'],\n",
    "    n_layers = model_args['model']['n_layers'],\n",
    "    patch_size = model_args['model']['patch_size'],\n",
    "    patch_stride = model_args['model']['patch_stride'],\n",
    ")\n",
    "\n",
    "# (Checkpoint loading... unchanged)\n",
    "checkpoint_path = os.path.join(model_path, 'best_checkpoint')\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    checkpoint_path = os.path.join(model_path, 'checkpoint/best_checkpoint')\n",
    "print(f\"Loading model checkpoint from: {checkpoint_path}\")\n",
    "checkpoint = torch.load(checkpoint_path, weights_only=False, map_location=device)\n",
    "for key in list(checkpoint['model_state_dict'].keys()):\n",
    "    checkpoint['model_state_dict'][key.replace(\"module.\", \"\")] = checkpoint['model_state_dict'].pop(key)\n",
    "    checkpoint['model_state_dict'][key.replace(\"_orig_mod.\", \"\")] = checkpoint['model_state_dict'].pop(key)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])  \n",
    "model.to(device) \n",
    "model.eval()\n",
    "\n",
    "# (Loss function definition... unchanged)\n",
    "ctc_loss = torch.nn.CTCLoss(blank=0, reduction='mean', zero_infinity=False)\n",
    "\n",
    "# (Data loading loop... unchanged)\n",
    "test_data = {}\n",
    "total_test_trials = 0\n",
    "for session in model_args['dataset']['sessions']:\n",
    "    if not os.path.exists(os.path.join(data_dir, session)):\n",
    "        print(f\"Session folder not found: {os.path.join(data_dir, session)}, skipping.\")\n",
    "        continue\n",
    "    files = [f for f in os.listdir(os.path.join(data_dir, session)) if f.endswith('.hdf5')]\n",
    "    if f'data_{eval_type}.hdf5' in files:\n",
    "        eval_file = os.path.join(data_dir, session, f'data_{eval_type}.hdf5')\n",
    "        data = load_h5py_file(eval_file, b2txt_csv_df)\n",
    "        test_data[session] = data\n",
    "        total_test_trials += len(test_data[session][\"neural_features\"])\n",
    "        print(f'Loaded {len(test_data[session][\"neural_features\"])} {eval_type} trials for session {session}.')\n",
    "print(f'Total number of {eval_type} trials: {total_test_trials}')\n",
    "print()\n",
    "\n",
    "\n",
    "# --- START FIX ---\n",
    "# This loop is modified to handle the numpy/tensor conversion\n",
    "with tqdm(total=total_test_trials, desc='Predicting phoneme sequences', unit='trial') as pbar:\n",
    "    for session, data in test_data.items():\n",
    "\n",
    "        data['logits'] = []\n",
    "        data['pred_seq'] = []\n",
    "        data['losses'] = [] \n",
    "        input_layer = model_args['dataset']['sessions'].index(session)\n",
    "        \n",
    "        for trial in range(len(data['neural_features'])):\n",
    "            neural_input = data['neural_features'][trial]\n",
    "            neural_input = np.expand_dims(neural_input, axis=0)\n",
    "            dtype = torch.bfloat16 if device.type != 'cpu' else torch.float32\n",
    "            neural_input_tensor = torch.tensor(neural_input, device=device, dtype=dtype)\n",
    "            \n",
    "            with torch.no_grad(): # Ensure no gradients are calculated\n",
    "                # runSingleDecodingStep returns a numpy array\n",
    "                logits_numpy = runSingleDecodingStep(neural_input_tensor, input_layer, model, model_args, device)\n",
    "            \n",
    "            # Store the numpy array for phoneme extraction later\n",
    "            data['logits'].append(logits_numpy)\n",
    "            \n",
    "            if eval_type == 'val':\n",
    "                # Convert logits back to a tensor for loss calculation\n",
    "                logits_tensor = torch.tensor(logits_numpy, device=device)\n",
    "            \n",
    "                true_seq = torch.tensor(data['seq_class_ids'][trial][0:data['seq_len'][trial]], device=device, dtype=torch.long)\n",
    "                true_len = torch.tensor([data['seq_len'][trial]], device=device, dtype=torch.long)\n",
    "                # Use the tensor's shape\n",
    "                adjusted_lens = torch.tensor([logits_tensor.shape[1]], device=device, dtype=torch.long)\n",
    "                \n",
    "                # Now perform log_softmax on the tensor\n",
    "                log_probs = torch.permute(logits_tensor.log_softmax(2), [1, 0, 2])\n",
    "                \n",
    "                loss = ctc_loss(log_probs, true_seq, adjusted_lens, true_len)\n",
    "                data['losses'].append(loss.item())\n",
    "\n",
    "            pbar.update(1)\n",
    "pbar.close()\n",
    "# --- END FIX ---\n",
    "\n",
    "\n",
    "# (Rest of the script is unchanged)\n",
    "for session, data in test_data.items():\n",
    "    data['pred_seq'] = []\n",
    "    for trial in range(len(data['logits'])):\n",
    "        logits = data['logits'][trial][0]\n",
    "        pred_seq = np.argmax(logits, axis=-1)\n",
    "        pred_seq = [int(p) for p in pred_seq if p != 0]\n",
    "        pred_seq = [pred_seq[i] for i in range(len(pred_seq)) if i == 0 or pred_seq[i] != pred_seq[i-1]]\n",
    "        pred_seq = [LOGIT_TO_PHONEME[p] for p in pred_seq]\n",
    "        data['pred_seq'].append(pred_seq)\n",
    "        \n",
    "        if eval_type == 'val':\n",
    "            block_num = data['block_num'][trial]\n",
    "            trial_num = data['trial_num'][trial]\n",
    "            print(f'Session: {session}, Block: {block_num}, Trial: {trial_num}')\n",
    "            sentence_label = data['sentence_label'][trial]\n",
    "            true_seq = data['seq_class_ids'][trial][0:data['seq_len'][trial]]\n",
    "            true_seq = [LOGIT_TO_PHONEME[p] for p in true_seq]\n",
    "            print(f'Sentence label:      {sentence_label}')\n",
    "            print(f'True sequence:       {\" \".join(true_seq)}')\n",
    "            print(f'Predicted Sequence:  {\" \".join(pred_seq)}')\n",
    "            print()\n",
    "\n",
    "output_dir = \"output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, f'phoneme_predictions_{time.strftime(\"%Y%m%d_%H%M%S\")}.csv')\n",
    "\n",
    "ids = []\n",
    "all_pred_phonemes = []\n",
    "all_true_phonemes = []\n",
    "trial_accuracy = []\n",
    "all_losses = [] \n",
    "\n",
    "total_edit_distance = 0\n",
    "total_phoneme_length = 0\n",
    "\n",
    "trial_id = 0\n",
    "for session, data in test_data.items():\n",
    "    if eval_type == 'val':\n",
    "        all_losses.extend(data['losses'])\n",
    "        \n",
    "    for trial_idx, pred_seq in enumerate(data['pred_seq']):\n",
    "        pred_phonemes = ' '.join(pred_seq)\n",
    "        if eval_type == 'val':\n",
    "            true_seq = data['seq_class_ids'][trial_idx][0:data['seq_len'][trial_idx]]\n",
    "            true_phonemes_list = [LOGIT_TO_PHONEME[p] for p in true_seq]\n",
    "            true_phonemes = ' '.join(true_phonemes_list)\n",
    "            \n",
    "            ed = editdistance.eval(pred_seq, true_phonemes_list)\n",
    "            true_len = len(true_phonemes_list)\n",
    "            \n",
    "            total_edit_distance += ed\n",
    "            total_phoneme_length += true_len\n",
    "            \n",
    "            acc = (1 - ed / true_len) if true_len > 0 else 0\n",
    "        else:\n",
    "            true_phonemes = None\n",
    "            acc = None\n",
    "\n",
    "        ids.append(trial_id)\n",
    "        all_pred_phonemes.append(pred_phonemes)\n",
    "        all_true_phonemes.append(true_phonemes)\n",
    "        trial_accuracy.append(acc)\n",
    "        trial_id += 1\n",
    "\n",
    "df_out = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'pred_phonemes': all_pred_phonemes,\n",
    "    'true_phonemes': all_true_phonemes,\n",
    "    'trial_accuracy': trial_accuracy\n",
    "})\n",
    "df_out.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Saved phoneme predictions, true sequences, and trial-level accuracy to {output_file}\")\n",
    "\n",
    "if eval_type == 'val':\n",
    "    if trial_accuracy:\n",
    "        avg_accuracy = sum([a for a in trial_accuracy if a is not None]) / len([a for a in trial_accuracy if a is not None])\n",
    "        print(f\"Average trial-level phoneme accuracy: {avg_accuracy:.4f}\")\n",
    "    else:\n",
    "        print(\"No trials found to calculate accuracy.\")\n",
    "\n",
    "    if total_phoneme_length > 0:\n",
    "        aggregate_per = total_edit_distance / total_phoneme_length\n",
    "        print(f\"Aggregate Phoneme Error Rate (PER): {aggregate_per:.4f}\")\n",
    "    else:\n",
    "        print(\"Could not calculate Aggregate PER: no validation phonemes found.\")\n",
    "        \n",
    "    if all_losses:\n",
    "        avg_loss = sum(all_losses) / len(all_losses)\n",
    "        print(f\"Sum Validation Loss: {sum(all_losses):.4f}\")\n",
    "        print(f\"Average Validation Loss: {avg_loss:.4f}\")\n",
    "    else:\n",
    "        print(\"Could not calculate average validation loss.\")\n",
    "\n",
    "# I got:\n",
    "# Average trial-level phoneme accuracy: 0.9027\n",
    "# Aggregate Phoneme Error Rate (PER): 0.1020\n",
    "# Sum Validation Loss: 1007.7086\n",
    "# Average Validation Loss: 0.7067"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare AdamW and SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /kaggle/working/nejm-brain-to-text/model_training/train_model_optimize.py\n",
    "\n",
    "import optuna\n",
    "from omegaconf import OmegaConf\n",
    "from rnn_trainer import BrainToTextDecoder_Trainer\n",
    "import os\n",
    "import numpy as np\n",
    "import torch \n",
    "import shutil\n",
    "\n",
    "# --- 1. Define the Objective Function for Optuna ---\n",
    "def objective(trial):\n",
    "    \n",
    "    args_path = 'rnn_args.yaml'\n",
    "    if not os.path.exists(args_path):\n",
    "        print(f\"Warning: '{args_path}' not found. Using pretrained model's args as template.\")\n",
    "        args_path = \"/kaggle/input/brain-to-text-25/t15_pretrained_rnn_baseline/t15_pretrained_rnn_baseline/checkpoint/args.yaml\"\n",
    "        \n",
    "    args = OmegaConf.load(args_path)\n",
    "\n",
    "    # Force the script to use the correct Kaggle data paths\n",
    "    args.dataset.dataset_dir = \"/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final\" \n",
    "    args.dataset.csv_path = \"/kaggle/working/nejm-brain-to-text/data/t15_copyTaskData_description.csv\"\n",
    "\n",
    "    # Give each trial a unique output and checkpoint directory\n",
    "    base_output_dir = args.output_dir\n",
    "    base_checkpoint_dir = args.checkpoint_dir\n",
    "    trial_id_str = f\"trial_{trial.number}\"\n",
    "    \n",
    "    args.output_dir = os.path.join(base_output_dir, trial_id_str)\n",
    "    args.checkpoint_dir = os.path.join(base_checkpoint_dir, trial_id_str)\n",
    "\n",
    "    # Remove existing directories\n",
    "    if os.path.exists(args.output_dir):\n",
    "        print(f\"Removing existing output directory: {args.output_dir}\")\n",
    "        shutil.rmtree(args.output_dir) # Recursively remove directory\n",
    "    if os.path.exists(args.checkpoint_dir):\n",
    "         print(f\"Removing existing checkpoint directory: {args.checkpoint_dir}\")\n",
    "         shutil.rmtree(args.checkpoint_dir) # Recursively remove directory\n",
    "\n",
    "    # Suggest new hyperparameters for this trial\n",
    "    # --- DO THIS LATER ---\n",
    "    # n_layers = trial.suggest_int('n_layers', 1, 4) \n",
    "    # n_units = trial.suggest_int('n_units', 256, 1024, step=128)\n",
    "    # rnn_dropout = trial.suggest_float('rnn_dropout', 0.1, 0.5)\n",
    "    # -----------------------\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"AdamW\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
    "\n",
    "    # Overwrite the default args with the new values from Optuna\n",
    "    # args.model.n_layers = n_layers\n",
    "    # args.model.n_units = n_units\n",
    "    # args.model.rnn_dropout = rnn_dropout\n",
    "    args.lr_max = lr\n",
    "\n",
    "    # Override to train faster\n",
    "    args.num_training_batches = 1000 \n",
    "    \n",
    "    print(f\"\\n--- Starting Trial {trial.number} ---\")\n",
    "    #print(f\"Params: n_layers={n_layers}, n_units={n_units}, rnn_dropout={rnn_dropout}, optimizer={optimizer_name}, lr={lr}\")\n",
    "    print(f\"Params: optimizer={optimizer_name}, lr={lr} (Using default model architecture)\")\n",
    "    print(f\"Training for {args.num_training_batches} batches.\")\n",
    "    print(f\"Output dir: {args.output_dir}\")\n",
    "\n",
    "    # Create trainer (initializes model)\n",
    "    trainer = BrainToTextDecoder_Trainer(args)\n",
    "\n",
    "    # --- Manually Create Optimizer and Scheduler ---\n",
    "    # Define param groups FIRST, filtering for requires_grad=True\n",
    "    bias_params = [p for name, p in trainer.model.named_parameters() if ('gru.bias' in name or 'out.bias' in name) and p.requires_grad]\n",
    "    day_params = [p for name, p in trainer.model.named_parameters() if 'day_' in name and p.requires_grad]\n",
    "    other_params = [p for name, p in trainer.model.named_parameters() if 'day_' not in name and 'gru.bias' not in name and 'out.bias' not in name and p.requires_grad]\n",
    "\n",
    "    # Structure the groups (handle case where day_params might be empty after filtering)\n",
    "    if day_params: # Only include day_params group if it's not empty\n",
    "        param_groups = [\n",
    "                {'params' : bias_params, 'weight_decay' : 0, 'group_type' : 'bias', 'lr': lr}, # Set LR here too\n",
    "                {'params' : day_params, 'lr' : args.lr_max_day, 'weight_decay' : args.weight_decay_day, 'group_type' : 'day_layer'},\n",
    "                {'params' : other_params, 'group_type' : 'other', 'lr': lr} # Set LR here too\n",
    "            ]\n",
    "    else: # No trainable day_params found\n",
    "        param_groups = [\n",
    "                {'params' : bias_params, 'weight_decay' : 0, 'group_type' : 'bias', 'lr': lr}, # Set LR here too\n",
    "                {'params' : other_params, 'group_type' : 'other', 'lr': lr} # Set LR here too\n",
    "            ]\n",
    "\n",
    "    # Now create the optimizer using the filtered groups\n",
    "    if optimizer_name == \"AdamW\":\n",
    "        trainer.optimizer = torch.optim.AdamW(\n",
    "            param_groups,\n",
    "            # lr is set per group above\n",
    "            betas = (args.beta0, args.beta1),\n",
    "            eps = args.epsilon,\n",
    "            # weight_decay handled per group\n",
    "            fused = True # Keep using fused if available\n",
    "        )\n",
    "                 \n",
    "    elif optimizer_name == \"SGD\":\n",
    "        trainer.optimizer = torch.optim.SGD(\n",
    "            param_groups, \n",
    "            # lr is set per group above\n",
    "            momentum=0.9,\n",
    "            # weight_decay handled per group\n",
    "        ) \n",
    "\n",
    "    # Recreate the learning rate scheduler using the NEW optimizer (this part should be fine now)\n",
    "    if args.lr_scheduler_type == 'linear':\n",
    "        trainer.learning_rate_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "            optimizer=trainer.optimizer, \n",
    "            start_factor=1.0,\n",
    "            end_factor=args.lr_min / args.lr_max, \n",
    "            total_iters=args.lr_decay_steps,\n",
    "        )\n",
    "    elif args.lr_scheduler_type == 'cosine':\n",
    "         # Check if create_cosine_lr_scheduler needs adjustment for potentially only 2 groups\n",
    "         # The original function handles 2 or 3 groups\n",
    "         # If day_params was empty, len(param_groups) will be 2, which is handled.\n",
    "         trainer.learning_rate_scheduler = trainer.create_cosine_lr_scheduler(trainer.optimizer)\n",
    "         \n",
    "    train_stats = trainer.train() \n",
    "\n",
    "    # Get the list of all validation Phoneme Error Rates\n",
    "    val_per_list = train_stats.get('val_PERs', []) \n",
    "    \n",
    "    # Get the best (minimum) PER from the list.\n",
    "    val_score = np.min(val_per_list) if val_per_list else 1.0 \n",
    "    \n",
    "    print(f\"Trial {trial.number} finished. Best (min) PER: {val_score}\")\n",
    "\n",
    "    return val_score\n",
    "\n",
    "# --- 2. Create the Study and Run It ---\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # We want to MINIMIZE the Phoneme Error Rate\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    \n",
    "    # Adjust n_trials as needed for time constraints\n",
    "    study.optimize(objective, n_trials=10) # Reduced trials for faster testing\n",
    "\n",
    "    print(\"\\n--- Optimization Finished ---\")\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(f\"  Value (Min PER): {trial.value}\")\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /kaggle/working/nejm-brain-to-text/model_training/ && \\\n",
    "python train_model_optimize.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result: \n",
    "\n",
    "Trial 0: optimizer=SGD, lr=0.00116, Final PER = 0.6147\n",
    "\n",
    "Trial 1: optimizer=AdamW, lr=8.36e-05, Final PER = 1.0000\n",
    "\n",
    "Trial 2: optimizer=AdamW, lr=0.00025, Final PER = 1.0000\n",
    "\n",
    "Trial 3: optimizer=SGD, lr=4.95e-05, Final PER = 1.0000\n",
    "\n",
    "Trial 4: optimizer=SGD, lr=3.34e-05, Final PER = 1.0000\n",
    "\n",
    "Trial 5: optimizer=SGD, lr=5.31e-05, Final PER = 1.0000\n",
    "\n",
    "Trial 6: optimizer=SGD, lr=0.00031, Final PER = 0.9975\n",
    "\n",
    "Trial 7: optimizer=SGD, lr=0.00344, Final PER = 0.4412 \n",
    "\n",
    "Trial 8: optimizer=AdamW, lr=0.00038, Final PER = 0.9980\n",
    "\n",
    "Trial 9: optimizer=SGD, lr=1.13e-05, Final PER = 0.9360\n",
    "\n",
    "SGD with not too small of a learning rate would be good\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test SGD with Different Hyperparam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried 2 sets: \n",
    "\n",
    "- Set 1: Conclusion - high momenutm + nesterov would be good \n",
    "\n",
    "Trial 0: lr=0.0028, momentum=0.944, nesterov=True -> PER = 0.3585\n",
    "\n",
    "Trial 1: lr=0.00026, momentum=0.934, nesterov=True -> PER = 0.9957\n",
    "\n",
    "Trial 2: lr=0.00028, momentum=0.821, nesterov=False -> PER = 1.0000\n",
    "\n",
    "Trial 3: lr=0.00062, momentum=0.916, nesterov=False -> PER = 0.8413\n",
    "\n",
    "Trial 4: lr=0.00548, momentum=0.871, nesterov=False -> PER = 0.4291\n",
    "\n",
    "Trial 5: lr=0.00192, momentum=0.815, nesterov=True -> PER = 0.6237\n",
    "\n",
    "Trial 6: lr=0.00071, momentum=0.986, nesterov=True -> PER = 0.3942\n",
    "\n",
    "Trial 7: lr=0.00064, momentum=0.932, nesterov=True -> PER = 0.6098\n",
    "\n",
    "Trial 8: lr=0.00030, momentum=0.967, nesterov=True -> PER = 0.6250\n",
    "\n",
    "Trial 9: lr=0.00053, momentum=0.952, nesterov=True -> PER = 0.9360\n",
    "\n",
    "- Set 2: Conclusion\n",
    "\n",
    "Trial 0: lr=0.0029, momentum=0.956, wd=2.5e-05, nesterov=True -> PER = 0.3118 \n",
    "\n",
    "Trial 1: lr=0.0030, momentum=0.945, wd=8.9e-05, nesterov=True -> PER = 0.3393\n",
    "\n",
    "Trial 2: lr=0.0029, momentum=0.954, wd=0.0014, nesterov=True -> PER = 0.3212\n",
    "\n",
    "Trial 3: lr=0.0030, momentum=0.974, wd=0.0079, nesterov=True -> PER = 0.2858 \n",
    "\n",
    "Trial 4: lr=0.0026, momentum=0.977, wd=0.0002, nesterov=True -> PER = 0.2848 \n",
    "\n",
    "Trial 5: lr=0.0026, momentum=0.947, wd=0.0004, nesterov=True -> PER = 0.3501\n",
    "\n",
    "Trial 6: lr=0.0028, momentum=0.989, wd=3.8e-05, nesterov=True -> PER = 0.2815\n",
    "\n",
    "Trial 7: lr=0.0026, momentum=0.957, wd=6.6e-05, nesterov=True -> PER = 0.3226\n",
    "\n",
    "Trial 8: lr=0.0030, momentum=0.964, wd=0.0023, nesterov=True -> PER = 0.2970\n",
    "\n",
    "Trial 9: lr=0.0028, momentum=0.984, wd=4.1e-05, nesterov=True -> PER = 0.2933\n",
    "\n",
    "Trial 10: lr=0.0032, momentum=0.990, wd=1.2e-05, nesterov=True -> PER = 0.2796 (Best)\n",
    "\n",
    "Trial 11: lr=0.0032, momentum=0.990, wd=1.2e-05, nesterov=True -> PER = 0.2825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /kaggle/working/nejm-brain-to-text/model_training/train_model_optimize_sgd.py\n",
    "\n",
    "import optuna\n",
    "from omegaconf import OmegaConf\n",
    "from rnn_trainer import BrainToTextDecoder_Trainer\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import shutil\n",
    "\n",
    "# --- 1. Define the Objective Function for Optuna ---\n",
    "def objective(trial):\n",
    "    \n",
    "    args_path = 'rnn_args.yaml'\n",
    "    # ... (rest of the initial setup: load args, set paths, unique dirs, remove old dirs) ...\n",
    "    if not os.path.exists(args_path):\n",
    "        print(f\"Warning: '{args_path}' not found. Using pretrained model's args as template.\")\n",
    "        args_path = \"/kaggle/input/brain-to-text-25/t15_pretrained_rnn_baseline/t15_pretrained_rnn_baseline/checkpoint/args.yaml\"\n",
    "    args = OmegaConf.load(args_path)\n",
    "    args.dataset.dataset_dir = \"/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final\" \n",
    "    args.dataset.csv_path = \"/kaggle/working/nejm-brain-to-text/data/t15_copyTaskData_description.csv\"\n",
    "    base_output_dir = args.output_dir\n",
    "    base_checkpoint_dir = args.checkpoint_dir\n",
    "    trial_id_str = f\"trial_{trial.number}\"\n",
    "    args.output_dir = os.path.join(base_output_dir, trial_id_str)\n",
    "    args.checkpoint_dir = os.path.join(base_checkpoint_dir, trial_id_str)\n",
    "    if os.path.exists(args.output_dir):\n",
    "        print(f\"Removing existing output directory: {args.output_dir}\")\n",
    "        shutil.rmtree(args.output_dir) \n",
    "    if os.path.exists(args.checkpoint_dir):\n",
    "         print(f\"Removing existing checkpoint directory: {args.checkpoint_dir}\")\n",
    "         shutil.rmtree(args.checkpoint_dir) \n",
    "\n",
    "    # --- Suggest Focused SGD Hyperparameters ---\n",
    "    lr = trial.suggest_float(\"lr\", 0.0026, 0.0032, log=False) \n",
    "    momentum = trial.suggest_float(\"momentum\", 0.94, 0.99) \n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-2, log=True) \n",
    "    nesterov = True \n",
    "\n",
    "    # --- Overwrite Learning Rate Arg ---\n",
    "    args.lr_max = lr \n",
    "    \n",
    "    args.num_training_batches = 1000 # Keep training short for testing\n",
    "    \n",
    "    print(f\"\\n--- Starting Trial {trial.number} ---\")\n",
    "    print(f\"Params: optimizer=SGD, lr={lr}, momentum={momentum}, weight_decay={weight_decay}, nesterov={nesterov} (Using default model architecture)\") \n",
    "    print(f\"Training for {args.num_training_batches} batches.\")\n",
    "    print(f\"Output dir: {args.output_dir}\")\n",
    "\n",
    "    # Create trainer (initializes model)\n",
    "    trainer = BrainToTextDecoder_Trainer(args) \n",
    "\n",
    "    # --- Manually Create SGD Optimizer with Filtered Groups and Tuned Params ---\n",
    "    \n",
    "    # 1. Manually define param lists, filtering for requires_grad=True\n",
    "    bias_params = [p for name, p in trainer.model.named_parameters() if ('gru.bias' in name or 'out.bias' in name) and p.requires_grad]\n",
    "    day_params = [p for name, p in trainer.model.named_parameters() if 'day_' in name and p.requires_grad]\n",
    "    other_params = [p for name, p in trainer.model.named_parameters() if 'day_' not in name and 'gru.bias' not in name and 'out.bias' not in name and p.requires_grad]\n",
    "\n",
    "    # 2. Structure the groups, applying specific settings\n",
    "    if day_params: \n",
    "        param_groups = [\n",
    "                {'params' : bias_params, 'weight_decay' : 0, 'lr': lr}, \n",
    "                {'params' : day_params, 'lr' : args.lr_max_day, 'weight_decay' : args.weight_decay_day}, # Keep day params separate\n",
    "                {'params' : other_params, 'lr': lr, 'weight_decay': weight_decay} # Apply tuned weight_decay here\n",
    "            ]\n",
    "    else: \n",
    "        param_groups = [\n",
    "                {'params' : bias_params, 'weight_decay' : 0, 'lr': lr}, \n",
    "                {'params' : other_params, 'lr': lr, 'weight_decay': weight_decay} # Apply tuned weight_decay here\n",
    "            ]\n",
    "            \n",
    "    # 3. Create the SGD optimizer using the filtered groups and tuned params\n",
    "    trainer.optimizer = torch.optim.SGD(\n",
    "        param_groups, \n",
    "        lr=lr, \n",
    "        momentum=momentum, \n",
    "        nesterov=nesterov \n",
    "        # weight_decay is handled per group\n",
    "    ) \n",
    "\n",
    "    # 4. Recreate the learning rate scheduler using the NEW optimizer \n",
    "    if args.lr_scheduler_type == 'linear':\n",
    "        trainer.learning_rate_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "            optimizer=trainer.optimizer, \n",
    "            start_factor=1.0,\n",
    "            end_factor=args.lr_min / args.lr_max, \n",
    "            total_iters=args.lr_decay_steps,\n",
    "        )\n",
    "    elif args.lr_scheduler_type == 'cosine':\n",
    "         trainer.learning_rate_scheduler = trainer.create_cosine_lr_scheduler(trainer.optimizer) \n",
    "         \n",
    "    train_stats = trainer.train() \n",
    "\n",
    "    # ... (rest of the function: get val_score, print, return) ...\n",
    "    val_per_list = train_stats.get('val_PERs', []) \n",
    "    val_score = np.min(val_per_list) if val_per_list else 1.0 \n",
    "    print(f\"Trial {trial.number} finished. Best (min) PER: {val_score}\")\n",
    "    return val_score\n",
    "    \n",
    "# --- (The __main__ section remains the same) ---\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=20) # Keep n_trials low for testing\n",
    "    print(\"\\n--- Optimization Finished ---\")\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"  Value (Min PER): {trial.value}\")\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /kaggle/working/nejm-brain-to-text/model_training/ && \\\n",
    "python train_model_optimize_sgd.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train full model with the SGD Param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New best test PER 0.1714 (at 10k batches); Average trial-level phoneme accuracy: 0.8345 (with 13,800 batches not 10k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /kaggle/working/nejm-brain-to-text/model_training/train_sgd_model.py\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from rnn_trainer import BrainToTextDecoder_Trainer\n",
    "import os\n",
    "import numpy as np\n",
    "import torch \n",
    "import shutil\n",
    "\n",
    "# --- 1. DEFINE YOUR WINNING PARAMETERS ---\n",
    "# (From Optuna Trial 10, the best one)\n",
    "BEST_LR = 0.00316\n",
    "BEST_MOMENTUM = 0.990\n",
    "BEST_WEIGHT_DECAY = 1.22e-05\n",
    "BEST_NESTEROV = True\n",
    "# ---\n",
    "\n",
    "print(\"--- Starting Full Training Run with Optimized SGD Params ---\")\n",
    "\n",
    "args_path = 'rnn_args.yaml'\n",
    "if not os.path.exists(args_path):\n",
    "    print(f\"Warning: '{args_path}' not found. Using pretrained model's args as template.\")\n",
    "    args_path = \"/kaggle/input/brain-to-text-25/t15_pretrained_rnn_baseline/t15_pretrained_rnn_baseline/checkpoint/args.yaml\"\n",
    "    \n",
    "args = OmegaConf.load(args_path)\n",
    "\n",
    "# Force the script to use the correct Kaggle data paths\n",
    "args.dataset.dataset_dir = \"/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final\" \n",
    "args.dataset.csv_path = \"/kaggle/working/nejm-brain-to-text/data/t15_copyTaskData_description.csv\"\n",
    "\n",
    "# --- 2. SET FULL TRAINING LENGTH ---\n",
    "# Use the default number of batches for a full training run\n",
    "args.num_training_batches = 10000 #original model 120000\n",
    "print(f\"Training for {args.num_training_batches} batches.\")\n",
    "\n",
    "# --- 3. SET UNIQUE OUTPUT DIRECTORY ---\n",
    "# We'll save this model in a special \"best_sgd_model\" folder\n",
    "new_output_dir = \"trained_models/baseline_rnn/best_sgd_model\"\n",
    "new_checkpoint_dir = \"trained_models/baseline_rnn/checkpoint/best_sgd_model\"\n",
    "args.output_dir = new_output_dir\n",
    "args.checkpoint_dir = new_checkpoint_dir\n",
    "\n",
    "# Remove old directories if they exist\n",
    "if os.path.exists(args.output_dir):\n",
    "    print(f\"Removing existing output directory: {args.output_dir}\")\n",
    "    shutil.rmtree(args.output_dir) \n",
    "if os.path.exists(args.checkpoint_dir):\n",
    "     print(f\"Removing existing checkpoint directory: {args.checkpoint_dir}\")\n",
    "     shutil.rmtree(args.checkpoint_dir) \n",
    "\n",
    "# --- 4. OVERWRITE ARGS WITH BEST PARAMS ---\n",
    "args.lr_max = BEST_LR\n",
    "\n",
    "print(f\"Params: optimizer=SGD, lr={BEST_LR}, momentum={BEST_MOMENTUM}, weight_decay={BEST_WEIGHT_DECAY}, nesterov={BEST_NESTEROV}\")\n",
    "print(f\"Output dir: {args.output_dir}\")\n",
    "\n",
    "# Create trainer (initializes model)\n",
    "trainer = BrainToTextDecoder_Trainer(args) \n",
    "\n",
    "# --- 5. MANUALLY CREATE THE OPTIMIZER AND SCHEDULER ---\n",
    "\n",
    "# 1. Manually define param lists, filtering for requires_grad=True\n",
    "bias_params = [p for name, p in trainer.model.named_parameters() if ('gru.bias' in name or 'out.bias' in name) and p.requires_grad]\n",
    "day_params = [p for name, p in trainer.model.named_parameters() if 'day_' in name and p.requires_grad]\n",
    "other_params = [p for name, p in trainer.model.named_parameters() if 'day_' not in name and 'gru.bias' not in name and 'out.bias' not in name and p.requires_grad]\n",
    "\n",
    "# 2. Structure the groups, applying specific settings\n",
    "if day_params: \n",
    "    param_groups = [\n",
    "            {'params' : bias_params, 'weight_decay' : 0, 'lr': BEST_LR}, \n",
    "            {'params' : day_params, 'lr' : args.lr_max_day, 'weight_decay' : args.weight_decay_day},\n",
    "            {'params' : other_params, 'lr': BEST_LR, 'weight_decay': BEST_WEIGHT_DECAY} \n",
    "        ]\n",
    "else: \n",
    "    param_groups = [\n",
    "            {'params' : bias_params, 'weight_decay' : 0, 'lr': BEST_LR}, \n",
    "            {'params' : other_params, 'lr': BEST_LR, 'weight_decay': BEST_WEIGHT_DECAY} \n",
    "        ]\n",
    "        \n",
    "# 3. Create the SGD optimizer\n",
    "trainer.optimizer = torch.optim.SGD(\n",
    "    param_groups, \n",
    "    lr=BEST_LR, \n",
    "    momentum=BEST_MOMENTUM, \n",
    "    nesterov=BEST_NESTEROV \n",
    ") \n",
    "\n",
    "# 4. Recreate the learning rate scheduler\n",
    "if args.lr_scheduler_type == 'linear':\n",
    "    trainer.learning_rate_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "        optimizer=trainer.optimizer, \n",
    "        start_factor=1.0,\n",
    "        end_factor=args.lr_min / args.lr_max, \n",
    "        total_iters=args.lr_decay_steps,\n",
    "    )\n",
    "elif args.lr_scheduler_type == 'cosine':\n",
    "     trainer.learning_rate_scheduler = trainer.create_cosine_lr_scheduler(trainer.optimizer) \n",
    "     \n",
    "# --- 6. RUN TRAINING ---\n",
    "print(\"Starting full model training...\")\n",
    "train_stats = trainer.train() \n",
    "\n",
    "val_per_list = train_stats.get('val_PERs', []) \n",
    "val_score = np.min(val_per_list) if val_per_list else 1.0 \n",
    "\n",
    "print(f\"\\n--- Full Training Finished ---\")\n",
    "print(f\"Final Best (min) PER: {val_score}\")\n",
    "print(f\"Your new model is saved in: {args.checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /kaggle/working/nejm-brain-to-text/model_training/ && \\\n",
    "python train_sgd_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# --- 1. Define all the paths ---\n",
    "eval_script = \"/kaggle/working/nejm-brain-to-text/model_training/evaluate_without_LLM_sgd.py\"\n",
    "# This path is now correct because the patched script will look \n",
    "# for 'args.yaml' directly inside it.\n",
    "model_path = \"/kaggle/working/nejm-brain-to-text/model_training/trained_models/baseline_rnn/checkpoint/best_sgd_model\"\n",
    "data_dir = \"/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final\"\n",
    "csv_path = \"/kaggle/working/nejm-brain-to-text/data/t15_copyTaskData_description.csv\"\n",
    "\n",
    "# --- 2. Set evaluation options ---\n",
    "eval_type = \"val\"\n",
    "gpu_number = 0\n",
    "\n",
    "# --- 3. Build and run the command ---\n",
    "cmd = f\"\"\"\n",
    "cd /kaggle/working/nejm-brain-to-text/model_training/ && \\\n",
    "python {eval_script} \\\n",
    "    --model_path {model_path} \\\n",
    "    --data_dir {data_dir} \\\n",
    "    --csv_path {csv_path} \\\n",
    "    --eval_type {eval_type} \\\n",
    "    --gpu_number {gpu_number}\n",
    "\"\"\"\n",
    "\n",
    "print(f\"--- Running evaluation on new model: {model_path} ---\")\n",
    "os.system(cmd)\n",
    "print(\"--- Evaluation finished. ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Baseline Model with Fewer Batches (10,000) to Compare with Previous SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "baseline model with 10k batches: Final Best (min) PER: 0.12702937424182892; Average trial-level phoneme accuracy: 0.8778"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /kaggle/working/nejm-brain-to-text/model_training/train_baseline_model.py\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from rnn_trainer import BrainToTextDecoder_Trainer\n",
    "import os\n",
    "import numpy as np\n",
    "import torch \n",
    "import shutil\n",
    "\n",
    "print(\"--- Starting Full Training Run with ORIGINAL BASELINE (AdamW) Params ---\")\n",
    "\n",
    "args_path = 'rnn_args.yaml'\n",
    "if not os.path.exists(args_path):\n",
    "    print(f\"Warning: '{args_path}' not found. Using pretrained model's args as template.\")\n",
    "    args_path = \"/kaggle/input/brain-to-text-25/t15_pretrained_rnn_baseline/t15_pretrained_rnn_baseline/checkpoint/args.yaml\"\n",
    "    \n",
    "args = OmegaConf.load(args_path)\n",
    "args.dataset.dataset_dir = \"/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final\" \n",
    "args.dataset.csv_path = \"/kaggle/working/nejm-brain-to-text/data/t15_copyTaskData_description.csv\"\n",
    "\n",
    "# --- SET TRAINING LENGTH ---\n",
    "args.num_training_batches = 10000 # Set to 10k for fair comparison\n",
    "print(f\"Training for {args.num_training_batches} batches.\")\n",
    "\n",
    "# --- SET UNIQUE OUTPUT DIRECTORY ---\n",
    "new_output_dir = \"trained_models/baseline_rnn/best_baseline_model\"\n",
    "new_checkpoint_dir = \"trained_models/baseline_rnn/checkpoint/best_baseline_model\"\n",
    "args.output_dir = new_output_dir\n",
    "args.checkpoint_dir = new_checkpoint_dir\n",
    "\n",
    "# Remove old directories if they exist\n",
    "if os.path.exists(args.output_dir):\n",
    "    print(f\"Removing existing output directory: {args.output_dir}\")\n",
    "    shutil.rmtree(args.output_dir) \n",
    "if os.path.exists(args.checkpoint_dir):\n",
    "     print(f\"Removing existing checkpoint directory: {args.checkpoint_dir}\")\n",
    "     shutil.rmtree(args.checkpoint_dir) \n",
    "\n",
    "# --- NO PARAMS TO OVERWRITE ---\n",
    "print(f\"Params: optimizer=AdamW (default), lr={args.lr_max} (default)\")\n",
    "print(f\"Output dir: {args.output_dir}\")\n",
    "\n",
    "# Create trainer (This will automatically create the default AdamW optimizer and scheduler)\n",
    "trainer = BrainToTextDecoder_Trainer(args) \n",
    "\n",
    "# --- NO MANUAL OPTIMIZER CREATION NEEDED ---\n",
    "\n",
    "# --- RUN TRAINING ---\n",
    "print(\"Starting baseline model training...\")\n",
    "train_stats = trainer.train() \n",
    "\n",
    "val_per_list = train_stats.get('val_PERs', []) \n",
    "val_score = np.min(val_per_list) if val_per_list else 1.0 \n",
    "\n",
    "print(f\"\\n--- Full Training Finished ---\")\n",
    "print(f\"Final Best (min) PER: {val_score}\")\n",
    "print(f\"Your new baseline model is saved in: {args.checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "eval_script = \"/kaggle/working/nejm-brain-to-text/model_training/evaluate_without_LLM.py\"\n",
    "data_dir = \"/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final\"\n",
    "csv_path = \"/kaggle/working/nejm-brain-to-text/data/t15_copyTaskData_description.csv\"\n",
    "model_path_baseline = \"/kaggle/working/nejm-brain-to-text/model_training/trained_models/baseline_rnn/checkpoint/best_baseline_model\"\n",
    "\n",
    "cmd_baseline = f\"\"\"\n",
    "cd /kaggle/working/nejm-brain-to-text/model_training/ && \\\n",
    "python {eval_script} \\\n",
    "    --model_path {model_path_baseline} \\\n",
    "    --data_dir {data_dir} \\\n",
    "    --csv_path {csv_path} \\\n",
    "    --eval_type \"val\" \\\n",
    "    --gpu_number 0\n",
    "\"\"\"\n",
    "print(f\"--- Evaluating BASELINE AdamW Model (trained 10k batches) ---\")\n",
    "os.system(cmd_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train SGD with different schedulers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trial 5 (Best): PER = 0.2363 Params: lr=0.0028, momentum=0.983, scheduler=linear\n",
    "\n",
    "Trial 0: PER = 0.2367 Params: lr=0.0031, momentum=0.976, scheduler=linear\n",
    "\n",
    "Trial 16: PER = 0.2406 Params: lr=0.0030, momentum=0.976, scheduler=linear\n",
    "\n",
    "Trial 13: PER = 0.2394 Params: lr=0.0028, momentum=0.981, scheduler=linear\n",
    "\n",
    "Trial 1: PER = 0.2493 Params: lr=0.0026, momentum=0.979, scheduler=linear\n",
    "\n",
    "Trial 15: PER = 0.2523 Params: lr=0.0030, momentum=0.970, scheduler=step, step_size=800\n",
    "\n",
    "Trial 14: PER = 0.2573 Params: lr=0.0027, momentum=0.986, scheduler=linear\n",
    "\n",
    "Trial 10: PER = 0.2796 Params: lr=0.0032, momentum=0.990, scheduler=step, step_size=800\n",
    "\n",
    "Trial 6: PER = 0.2815 Params: lr=0.0028, momentum=0.989, scheduler=linear\n",
    "\n",
    "Trial 11: PER = 0.2825 Params: lr=0.0032, momentum=0.990, scheduler=linear\n",
    "\n",
    "Trial 7: PER = 0.2836 Params: lr=0.0031, momentum=0.988, scheduler=cosine\n",
    "\n",
    "Trial 19: PER = 0.2872 Params: lr=0.0029, momentum=0.977, scheduler=cosine\n",
    "\n",
    "Trial 4: PER = 0.2970 Params: lr=0.0029, momentum=0.974, scheduler=step, step_size=500\n",
    "\n",
    "Trial 8: PER = 0.2415 Params: lr=0.0032, momentum=0.985, scheduler=linear\n",
    "\n",
    "Trial 9: PER = 0.3084 Params: lr=0.0026, momentum=0.976, scheduler=step, step_size=500\n",
    "\n",
    "Trial 2: PER = 0.2803 Params: lr=0.0028, momentum=0.990, scheduler=cosine\n",
    "\n",
    "Trial 12: PER = 0.2387 Params: lr=0.0030, momentum=0.974, scheduler=linear\n",
    "\n",
    "Trial 18: PER = 0.3793 Params: lr=0.0031, momentum=0.979, scheduler=step, step_size=300\n",
    "\n",
    "Trial 17: PER = 0.2461 Params: lr=0.0027, momentum=0.984, scheduler=linear\n",
    "\n",
    "Trial 3: PER = 0.2415 Params: lr=0.0027, momentum=0.978, scheduler=linear\n",
    "\n",
    "Tested Trial 5 on full model with 10k batches: Final Best (min) PER: 0.14324022829532623 (did not test accuracy since the session timed out)\n",
    "\n",
    "(vs baseline model with 10k batches: Final Best (min) PER: 0.12702937424182892; Average trial-level phoneme accuracy: 0.8778)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /kaggle/working/nejm-brain-to-text/model_training/train_model_optimize_sgd.py\n",
    "\n",
    "import optuna\n",
    "from omegaconf import OmegaConf\n",
    "from rnn_trainer import BrainToTextDecoder_Trainer\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import shutil\n",
    "\n",
    "# --- 1. Define the Objective Function for Optuna ---\n",
    "def objective(trial):\n",
    "    \n",
    "    args_path = 'rnn_args.yaml'\n",
    "    if not os.path.exists(args_path):\n",
    "        print(f\"Warning: '{args_path}' not found. Using pretrained model's args as template.\")\n",
    "        args_path = \"/kaggle/input/brain-to-text-25/t15_pretrained_rnn_baseline/t15_pretrained_rnn_baseline/checkpoint/args.yaml\"\n",
    "    args = OmegaConf.load(args_path)\n",
    "    args.dataset.dataset_dir = \"/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final\" \n",
    "    args.dataset.csv_path = \"/kaggle/working/nejm-brain-to-text/data/t15_copyTaskData_description.csv\"\n",
    "    base_output_dir = args.output_dir\n",
    "    base_checkpoint_dir = args.checkpoint_dir\n",
    "    trial_id_str = f\"trial_{trial.number}\"\n",
    "    args.output_dir = os.path.join(base_output_dir, trial_id_str)\n",
    "    args.checkpoint_dir = os.path.join(base_checkpoint_dir, trial_id_str)\n",
    "    if os.path.exists(args.output_dir):\n",
    "        print(f\"Removing existing output directory: {args.output_dir}\")\n",
    "        shutil.rmtree(args.output_dir) \n",
    "    if os.path.exists(args.checkpoint_dir):\n",
    "         print(f\"Removing existing checkpoint directory: {args.checkpoint_dir}\")\n",
    "         shutil.rmtree(args.checkpoint_dir) \n",
    "\n",
    "    # --- Suggest Focused SGD Hyperparameters ---\n",
    "    lr = trial.suggest_float(\"lr\", 0.0026, 0.0032, log=False) # Narrowed LR range\n",
    "    momentum = trial.suggest_float(\"momentum\", 0.97, 0.99) # Narrowed momentum range\n",
    "    weight_decay = args.weight_decay # Use default weight decay\n",
    "    nesterov = True \n",
    "\n",
    "    scheduler_type = trial.suggest_categorical(\"scheduler\", [\"linear\", \"cosine\", \"step\"])\n",
    "    if scheduler_type == \"step\":\n",
    "        # step_size must be < num_training_batches to have an effect\n",
    "        step_size = trial.suggest_int(\"step_size\", 300, 800, step=100)\n",
    "        gamma = 0.1\n",
    "\n",
    "    # --- Overwrite Learning Rate Arg ---\n",
    "    args.lr_max = lr \n",
    "    \n",
    "    args.num_training_batches = 1000 # Keep training short for testing\n",
    "    \n",
    "    print(f\"\\n--- Starting Trial {trial.number} ---\")\n",
    "    print(f\"Params: optimizer=SGD, lr={lr}, momentum={momentum}, wd={weight_decay} (default), nesterov={nesterov}\") \n",
    "    print(f\"Scheduler: {scheduler_type}\")\n",
    "    if scheduler_type == \"step\":\n",
    "        print(f\"StepLR Params: step_size={step_size}, gamma={gamma}\")\n",
    "    print(f\"Training for {args.num_training_batches} batches.\")\n",
    "    print(f\"Output dir: {args.output_dir}\")\n",
    "\n",
    "    # Create trainer (initializes model)\n",
    "    trainer = BrainToTextDecoder_Trainer(args) \n",
    "\n",
    "    # --- Manually Create SGD Optimizer with Filtered Groups and Tuned Params ---\n",
    "    \n",
    "    # 1. Manually define param lists\n",
    "    bias_params = [p for name, p in trainer.model.named_parameters() if ('gru.bias' in name or 'out.bias' in name) and p.requires_grad]\n",
    "    day_params = [p for name, p in trainer.model.named_parameters() if 'day_' in name and p.requires_grad]\n",
    "    other_params = [p for name, p in trainer.model.named_parameters() if 'day_' not in name and 'gru.bias' not in name and 'out.bias' not in name and p.requires_grad]\n",
    "\n",
    "    # 2. Structure the groups\n",
    "    if day_params: \n",
    "        param_groups = [\n",
    "                {'params' : bias_params, 'weight_decay' : 0, 'lr': lr}, \n",
    "                {'params' : day_params, 'lr' : args.lr_max_day, 'weight_decay' : args.weight_decay_day},\n",
    "                {'params' : other_params, 'lr': lr, 'weight_decay': weight_decay} \n",
    "            ]\n",
    "    else: \n",
    "        param_groups = [\n",
    "                {'params' : bias_params, 'weight_decay' : 0, 'lr': lr}, \n",
    "                {'params' : other_params, 'lr': lr, 'weight_decay': weight_decay} \n",
    "            ]\n",
    "            \n",
    "    # 3. Create the SGD optimizer\n",
    "    trainer.optimizer = torch.optim.SGD(\n",
    "        param_groups, \n",
    "        lr=lr, \n",
    "        momentum=momentum, \n",
    "        nesterov=nesterov \n",
    "    ) \n",
    "\n",
    "    # --- 4. Recreate the learning rate scheduler BASED ON TRIAL ---\n",
    "    if scheduler_type == 'linear':\n",
    "        print(\"Using LinearLR scheduler.\")\n",
    "        trainer.learning_rate_scheduler = torch.optim.lr_scheduler.LinearLR(\n",
    "            optimizer=trainer.optimizer, \n",
    "            start_factor=1.0,\n",
    "            end_factor=args.lr_min / args.lr_max, \n",
    "            total_iters=args.lr_decay_steps, # Uses default decay steps\n",
    "        )\n",
    "    elif scheduler_type == 'cosine':\n",
    "        print(\"Using CosineLR scheduler.\")\n",
    "        trainer.learning_rate_scheduler = trainer.create_cosine_lr_scheduler(trainer.optimizer) \n",
    "    elif scheduler_type == 'step':\n",
    "        print(f\"Using StepLR scheduler with step_size={step_size}, gamma={gamma}.\")\n",
    "        trainer.learning_rate_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "            optimizer=trainer.optimizer,\n",
    "            step_size=step_size,\n",
    "            gamma=gamma\n",
    "        )\n",
    "         \n",
    "    train_stats = trainer.train() \n",
    "    val_per_list = train_stats.get('val_PERs', []) \n",
    "    val_score = np.min(val_per_list) if val_per_list else 1.0 \n",
    "    print(f\"Trial {trial.number} finished. Best (min) PER: {val_score}\")\n",
    "    return val_score\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction='minimize')\n",
    "    study.optimize(objective, n_trials=20)\n",
    "    \n",
    "    print(\"\\n--- Optimization Finished ---\")\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    \n",
    "    print(f\"  Value (Min PER): {trial.value}\")\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
