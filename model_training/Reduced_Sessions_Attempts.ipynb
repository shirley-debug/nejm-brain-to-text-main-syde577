{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /kaggle/working/nejm-brain-to-text/model_training/train_baseline_model.py\n",
    "from omegaconf import OmegaConf\n",
    "from rnn_trainer import BrainToTextDecoder_Trainer\n",
    "import os\n",
    "import numpy as np\n",
    "import torch \n",
    "import shutil\n",
    "\n",
    "args_path = 'rnn_args.yaml'\n",
    "if not os.path.exists(args_path):\n",
    "    print(f\"Warning: '{args_path}' not found. Using pretrained model's args as template.\")\n",
    "    args_path = \"/kaggle/input/brain-to-text-25/t15_pretrained_rnn_baseline/t15_pretrained_rnn_baseline/checkpoint/args.yaml\"\n",
    "    \n",
    "args = OmegaConf.load(args_path)\n",
    "\n",
    "# Force the script to use the correct Kaggle data paths\n",
    "args.dataset.dataset_dir = \"/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final\" \n",
    "args.dataset.csv_path = \"/kaggle/working/nejm-brain-to-text/data/t15_copyTaskData_description.csv\"\n",
    "\n",
    "# Train on first 3 sessions, reserve 4th for testing\n",
    "args.dataset.sessions = [\n",
    "    't15.2023.08.11',\n",
    "    't15.2023.08.13',\n",
    "    't15.2023.08.18',\n",
    "    't15.2023.08.20'\n",
    "]\n",
    "\n",
    "# Update n_days to match number of sessions\n",
    "args.model.n_days = len(args.dataset.sessions)\n",
    "\n",
    "# Update dataset probabilities\n",
    "# Note: t15.2023.08.11 has no val data, so set its val probability to 0\n",
    "if hasattr(args.dataset, 'dataset_probability_train'):\n",
    "    args.dataset.dataset_probability_train = [1.0, 1.0, 1.0, 1.0]\n",
    "if hasattr(args.dataset, 'dataset_probability_val'):\n",
    "    # Set to 0 for days without validation data\n",
    "    args.dataset.dataset_probability_val = [0.0, 1.0, 1.0, 0.0]\n",
    "\n",
    "# Disable logging of individual day validation PER to avoid division by zero\n",
    "args.log_individual_day_val_PER = False\n",
    "\n",
    "args.num_training_batches = 10000\n",
    "print(f\"\\nTraining for {args.num_training_batches} batches.\")\n",
    "args.days_per_batch = 2\n",
    "print(f\"\\nTraining for {args.days_per_batch} days per batches.\")\n",
    "args.batch_size = 16\n",
    "print(f\"\\nTraining for batch size = {args.batch_size}.\")\n",
    "\n",
    "\n",
    "# Set output directories\n",
    "new_output_dir = \"trained_models/baseline_rnn/progressive_training\"\n",
    "new_checkpoint_dir = \"trained_models/baseline_rnn/checkpoint/progressive_training\"\n",
    "args.output_dir = new_output_dir\n",
    "args.checkpoint_dir = new_checkpoint_dir\n",
    "\n",
    "# Remove old directories if they exist\n",
    "if os.path.exists(args.output_dir):\n",
    "    print(f\"Removing existing output directory: {args.output_dir}\")\n",
    "    shutil.rmtree(args.output_dir) \n",
    "if os.path.exists(args.checkpoint_dir):\n",
    "    print(f\"Removing existing checkpoint directory: {args.checkpoint_dir}\")\n",
    "    shutil.rmtree(args.checkpoint_dir) \n",
    "\n",
    "# Verify data files exist\n",
    "print(\"\\nVerifying data files:\")\n",
    "for i, session in enumerate(args.dataset.sessions):\n",
    "    train_path = os.path.join(args.dataset.dataset_dir, session, 'data_train.hdf5')\n",
    "    val_path = os.path.join(args.dataset.dataset_dir, session, 'data_val.hdf5')\n",
    "    test_path = os.path.join(args.dataset.dataset_dir, session, 'data_test.hdf5')\n",
    "    \n",
    "    train_exists = os.path.exists(train_path)\n",
    "    val_exists = os.path.exists(val_path)\n",
    "    test_exists = os.path.exists(test_path)\n",
    "    \n",
    "    if not train_exists:\n",
    "        print(f\"    WARNING: Missing training data!\")\n",
    "\n",
    "# CREATE TRAINER\n",
    "print(\"\\nInitializing trainer...\")\n",
    "trainer = BrainToTextDecoder_Trainer(args) \n",
    "\n",
    "train_stats = trainer.train() \n",
    "\n",
    "val_per_list = train_stats.get('val_PERs', []) \n",
    "val_score = np.min(val_per_list) if val_per_list else 1.0 \n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(f\"--- Base Model Training Finished ---\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Final Best (min) Validation PER: {val_score:.4f}\")\n",
    "print(f\"Model checkpoint saved in: {args.checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd /kaggle/working/nejm-brain-to-text/model_training/ && \\\n",
    "python train_baseline_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile /kaggle/working/nejm-brain-to-text/model_training/evaluate_without_LLM.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import redis\n",
    "from omegaconf import OmegaConf\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import editdistance\n",
    "import argparse\n",
    "\n",
    "from rnn_model import GRUDecoder\n",
    "from evaluate_model_helpers import *\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Evaluate a pretrained RNN model on the copy task dataset.')\n",
    "parser.add_argument('--model_path', type=str, default='../data/t15_pretrained_rnn_baseline',\n",
    "                    help='Path to the pretrained model directory (relative to the current working directory).')\n",
    "parser.add_argument('--data_dir', type=str, default='../data/hdf5_data_final',\n",
    "                    help='Path to the dataset directory (relative to the current working directory).')\n",
    "parser.add_argument('--eval_type', type=str, default='test', choices=['val', 'test'],\n",
    "                    help='Evaluation type: \"val\" for validation set, \"test\" for test set. '\n",
    "                         'If \"test\", ground truth is not available.')\n",
    "parser.add_argument('--csv_path', type=str, default='../data/t15_copyTaskData_description.csv',\n",
    "                    help='Path to the CSV file with metadata about the dataset (relative to the current working directory).')\n",
    "parser.add_argument('--gpu_number', type=int, default=1,\n",
    "                    help='GPU number to use for RNN model inference. Set to -1 to use CPU.')\n",
    "parser.add_argument('--session', type=str, default=None,\n",
    "                    help='Specify a single session to evaluate (e.g., \"t15.2023.08.20\").')\n",
    "args = parser.parse_args()\n",
    "model_path = args.model_path\n",
    "data_dir = args.data_dir\n",
    "eval_type = args.eval_type  \n",
    "b2txt_csv_df = pd.read_csv(args.csv_path)\n",
    "model_args_path = os.path.join(model_path, 'args.yaml')\n",
    "if not os.path.exists(model_args_path):\n",
    "    model_args_path = os.path.join(model_path, 'checkpoint/args.yaml')\n",
    "print(f\"Loading model args from: {model_args_path}\")\n",
    "model_args = OmegaConf.load(model_args_path)\n",
    "gpu_number = args.gpu_number\n",
    "if torch.cuda.is_available() and gpu_number >= 0:\n",
    "    if gpu_number >= torch.cuda.device_count():\n",
    "        raise ValueError(f'GPU number {gpu_number} is out of range. Available GPUs: {torch.cuda.device_count()}')\n",
    "    device = f'cuda:{gpu_number}'\n",
    "    device = torch.device(device)\n",
    "    print(f'Using {device} for model inference.')\n",
    "else:\n",
    "    if gpu_number >= 0:\n",
    "        print(f'GPU number {gpu_number} requested but not available.')\n",
    "    print('Using CPU for model inference.')\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "model = GRUDecoder(\n",
    "    neural_dim = model_args['model']['n_input_features'],\n",
    "    n_units = model_args['model']['n_units'], \n",
    "    n_days = len(model_args['dataset']['sessions']),\n",
    "    n_classes = model_args['dataset']['n_classes'],\n",
    "    rnn_dropout = model_args['model']['rnn_dropout'],\n",
    "    input_dropout = model_args['model']['input_network']['input_layer_dropout'],\n",
    "    n_layers = model_args['model']['n_layers'],\n",
    "    patch_size = model_args['model']['patch_size'],\n",
    "    patch_stride = model_args['model']['patch_stride'],\n",
    ")\n",
    "\n",
    "checkpoint_path = os.path.join(model_path, 'best_checkpoint')\n",
    "if not os.path.exists(checkpoint_path):\n",
    "    checkpoint_path = os.path.join(model_path, 'checkpoint/best_checkpoint')\n",
    "print(f\"Loading model checkpoint from: {checkpoint_path}\")\n",
    "checkpoint = torch.load(checkpoint_path, weights_only=False, map_location=device)\n",
    "for key in list(checkpoint['model_state_dict'].keys()):\n",
    "    checkpoint['model_state_dict'][key.replace(\"module.\", \"\")] = checkpoint['model_state_dict'].pop(key)\n",
    "    checkpoint['model_state_dict'][key.replace(\"_orig_mod.\", \"\")] = checkpoint['model_state_dict'].pop(key)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])  \n",
    "model.to(device) \n",
    "model.eval()\n",
    "\n",
    "ctc_loss = torch.nn.CTCLoss(blank=0, reduction='mean', zero_infinity=False)\n",
    "\n",
    "# Determine which sessions to evaluate\n",
    "sessions_to_evaluate = model_args['dataset']['sessions']\n",
    "if args.session: # If a specific session was passed\n",
    "    if args.session in sessions_to_evaluate:\n",
    "        sessions_to_evaluate = [args.session] # Overwrite the list to only contain this one session\n",
    "        print(f\"--- Evaluating ONLY specified session: {args.session} ---\")\n",
    "    else:\n",
    "        raise ValueError(f\"Session '{args.session}' not found in model config list.\")\n",
    "\n",
    "test_data = {}\n",
    "total_test_trials = 0\n",
    "for session in sessions_to_evaluate: # Now loop over the (potentially) filtered list\n",
    "    if not os.path.exists(os.path.join(data_dir, session)):\n",
    "        print(f\"Session folder not found: {os.path.join(data_dir, session)}, skipping.\")\n",
    "        continue\n",
    "    files = [f for f in os.listdir(os.path.join(data_dir, session)) if f.endswith('.hdf5')]\n",
    "    if f'data_{eval_type}.hdf5' in files:\n",
    "        eval_file = os.path.join(data_dir, session, f'data_{eval_type}.hdf5')\n",
    "        data = load_h5py_file(eval_file, b2txt_csv_df)\n",
    "        test_data[session] = data\n",
    "        total_test_trials += len(test_data[session][\"neural_features\"])\n",
    "        print(f'Loaded {len(test_data[session][\"neural_features\"])} {eval_type} trials for session {session}.')\n",
    "print(f'Total number of {eval_type} trials: {total_test_trials}')\n",
    "print()\n",
    "\n",
    "with tqdm(total=total_test_trials, desc='Predicting phoneme sequences', unit='trial') as pbar:\n",
    "    for session, data in test_data.items():\n",
    "\n",
    "        data['logits'] = []\n",
    "        data['pred_seq'] = []\n",
    "        data['losses'] = [] \n",
    "        input_layer = model_args['dataset']['sessions'].index(session)\n",
    "        \n",
    "        for trial in range(len(data['neural_features'])):\n",
    "            neural_input = data['neural_features'][trial]\n",
    "            neural_input = np.expand_dims(neural_input, axis=0)\n",
    "            dtype = torch.bfloat16 if device.type != 'cpu' else torch.float32\n",
    "            neural_input_tensor = torch.tensor(neural_input, device=device, dtype=dtype)\n",
    "            \n",
    "            with torch.no_grad(): # Ensure no gradients are calculated\n",
    "                # runSingleDecodingStep returns a numpy array\n",
    "                logits_numpy = runSingleDecodingStep(neural_input_tensor, input_layer, model, model_args, device)\n",
    "            \n",
    "            # Store the numpy array for phoneme extraction later\n",
    "            data['logits'].append(logits_numpy)\n",
    "            \n",
    "            if eval_type == 'val':\n",
    "                # Convert logits back to a tensor for loss calculation\n",
    "                logits_tensor = torch.tensor(logits_numpy, device=device)\n",
    "            \n",
    "                true_seq = torch.tensor(data['seq_class_ids'][trial][0:data['seq_len'][trial]], device=device, dtype=torch.long)\n",
    "                true_len = torch.tensor([data['seq_len'][trial]], device=device, dtype=torch.long)\n",
    "                # Use the tensor's shape\n",
    "                adjusted_lens = torch.tensor([logits_tensor.shape[1]], device=device, dtype=torch.long)\n",
    "                \n",
    "                # Now perform log_softmax on the tensor\n",
    "                log_probs = torch.permute(logits_tensor.log_softmax(2), [1, 0, 2])\n",
    "                \n",
    "                loss = ctc_loss(log_probs, true_seq, adjusted_lens, true_len)\n",
    "                data['losses'].append(loss.item())\n",
    "\n",
    "            pbar.update(1)\n",
    "pbar.close()\n",
    "\n",
    "for session, data in test_data.items():\n",
    "    data['pred_seq'] = []\n",
    "    for trial in range(len(data['logits'])):\n",
    "        logits = data['logits'][trial][0]\n",
    "        pred_seq = np.argmax(logits, axis=-1)\n",
    "        pred_seq = [int(p) for p in pred_seq if p != 0]\n",
    "        pred_seq = [pred_seq[i] for i in range(len(pred_seq)) if i == 0 or pred_seq[i] != pred_seq[i-1]]\n",
    "        pred_seq = [LOGIT_TO_PHONEME[p] for p in pred_seq]\n",
    "        data['pred_seq'].append(pred_seq)\n",
    "        \n",
    "        if eval_type == 'val':\n",
    "            block_num = data['block_num'][trial]\n",
    "            trial_num = data['trial_num'][trial]\n",
    "            print(f'Session: {session}, Block: {block_num}, Trial: {trial_num}')\n",
    "            sentence_label = data['sentence_label'][trial]\n",
    "            true_seq = data['seq_class_ids'][trial][0:data['seq_len'][trial]]\n",
    "            true_seq = [LOGIT_TO_PHONEME[p] for p in true_seq]\n",
    "            print(f'Sentence label:      {sentence_label}')\n",
    "            print(f'True sequence:       {\" \".join(true_seq)}')\n",
    "            print(f'Predicted Sequence:  {\" \".join(pred_seq)}')\n",
    "            print()\n",
    "\n",
    "output_dir = \"output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_file = os.path.join(output_dir, f'phoneme_predictions_{time.strftime(\"%Y%m%d_%H%M%S\")}.csv')\n",
    "\n",
    "ids = []\n",
    "all_pred_phonemes = []\n",
    "all_true_phonemes = []\n",
    "trial_accuracy = []\n",
    "all_losses = [] \n",
    "\n",
    "total_edit_distance = 0\n",
    "total_phoneme_length = 0\n",
    "\n",
    "trial_id = 0\n",
    "for session, data in test_data.items():\n",
    "    if eval_type == 'val':\n",
    "        all_losses.extend(data['losses'])\n",
    "        \n",
    "    for trial_idx, pred_seq in enumerate(data['pred_seq']):\n",
    "        pred_phonemes = ' '.join(pred_seq)\n",
    "        if eval_type == 'val':\n",
    "            true_seq = data['seq_class_ids'][trial_idx][0:data['seq_len'][trial_idx]]\n",
    "            true_phonemes_list = [LOGIT_TO_PHONEME[p] for p in true_seq]\n",
    "            true_phonemes = ' '.join(true_phonemes_list)\n",
    "            \n",
    "            ed = editdistance.eval(pred_seq, true_phonemes_list)\n",
    "            true_len = len(true_phonemes_list)\n",
    "            \n",
    "            total_edit_distance += ed\n",
    "            total_phoneme_length += true_len\n",
    "            \n",
    "            acc = (1 - ed / true_len) if true_len > 0 else 0\n",
    "        else:\n",
    "            true_phonemes = None\n",
    "            acc = None\n",
    "\n",
    "        ids.append(trial_id)\n",
    "        all_pred_phonemes.append(pred_phonemes)\n",
    "        all_true_phonemes.append(true_phonemes)\n",
    "        trial_accuracy.append(acc)\n",
    "        trial_id += 1\n",
    "\n",
    "df_out = pd.DataFrame({\n",
    "    'id': ids,\n",
    "    'pred_phonemes': all_pred_phonemes,\n",
    "    'true_phonemes': all_true_phonemes,\n",
    "    'trial_accuracy': trial_accuracy\n",
    "})\n",
    "df_out.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Saved phoneme predictions, true sequences, and trial-level accuracy to {output_file}\")\n",
    "\n",
    "if eval_type == 'val':\n",
    "    if trial_accuracy:\n",
    "        avg_accuracy = sum([a for a in trial_accuracy if a is not None]) / len([a for a in trial_accuracy if a is not None])\n",
    "        print(f\"Average trial-level phoneme accuracy: {avg_accuracy:.4f}\")\n",
    "    else:\n",
    "        print(\"No trials found to calculate accuracy.\")\n",
    "\n",
    "    if total_phoneme_length > 0:\n",
    "        aggregate_per = total_edit_distance / total_phoneme_length\n",
    "        print(f\"Aggregate Phoneme Error Rate (PER): {aggregate_per:.4f}\")\n",
    "    else:\n",
    "        print(\"Could not calculate Aggregate PER: no validation phonemes found.\")\n",
    "        \n",
    "    if all_losses:\n",
    "        avg_loss = sum(all_losses) / len(all_losses)\n",
    "        print(f\"Sum Validation Loss: {sum(all_losses):.4f}\")\n",
    "        print(f\"Average Validation Loss: {avg_loss:.4f}\")\n",
    "    else:\n",
    "        print(\"Could not calculate average validation loss.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "eval_script = \"/kaggle/working/nejm-brain-to-text/model_training/evaluate_without_LLM.py\"\n",
    "model_path = \"/kaggle/working/nejm-brain-to-text/model_training/trained_models/baseline_rnn/checkpoint/progressive_training\"\n",
    "data_dir = \"/kaggle/input/brain-to-text-25/t15_copyTask_neuralData/hdf5_data_final\"\n",
    "csv_path = \"/kaggle/working/nejm-brain-to-text/data/t15_copyTaskData_description.csv\"\n",
    "\n",
    "# USE VAL INSTEAD OF TEST\n",
    "eval_type = \"val\"  # This has ground truth labels\n",
    "gpu_number = 0\n",
    "target_session = \"t15.2023.08.20\"\n",
    "\n",
    "cmd = f\"\"\"\n",
    "cd /kaggle/working/nejm-brain-to-text/model_training/ && \\\n",
    "python {eval_script} \\\n",
    "    --model_path {model_path} \\\n",
    "    --data_dir {data_dir} \\\n",
    "    --csv_path {csv_path} \\\n",
    "    --eval_type {eval_type} \\\n",
    "    --gpu_number {gpu_number}\\\n",
    "    --session {target_session}\n",
    "\"\"\"\n",
    "print(f\"Model: {model_path}\")\n",
    "print(f\"Eval type: {eval_type}\")\n",
    "\n",
    "os.system(cmd)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
